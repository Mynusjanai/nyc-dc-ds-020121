{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import chi2_contingency # chi-squared test with similar proportions\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.stats import weightstats as stests # z-test code\n",
    "from statsmodels.stats.proportion import proportions_ztest # proportions z-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score for population data for a single point in relation to a distribution of points\n",
    "z = (x_bar - mu)/(std) # Where mean of sample data (x_bar) - population mean / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score for when we are working with a sampling distribution:\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical Value of the Z score\n",
    "z_critical_val = st.norm.ppf(1-.05) # Where alpha is '.05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crit val for Z scores where comparing in 97% confidence\n",
    "zcrit_val1 = st.norm.ppf(1-.025)\n",
    "zcrit_val2 = st.norm.ppf(1-.975)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python function one sided Z-score from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce\n",
    "ztest ,pval = stests.ztest(df['bp_before'], x2=None, value=156)\n",
    "print(float(pval))\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python function two sided Z-score from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce\n",
    "ztest ,pval1 = stests.ztest(df['bp_before'], x2=df['bp_after'], value=0,alternative='two-sided')\n",
    "print(float(pval1))\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Percentile & Probability (hypothesis testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use stats to calculate the percentile / probablility of getting given z score OR higher\n",
    "print(\"Percentile = \", stats.norm.cdf(z)) # can use for t-value also\n",
    "\n",
    "# We can also use the survival function to calculate the probability\n",
    "print(\"Probability = \", stats.norm.sf(z)) # can use for t-value also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparing 2 means to see if they are equal or not equal. Correlation does not equal causation however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-critical value for 1 tailed test (hypothesis testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Python to get the t-statistic & P-value for a 1 sample t-test:\n",
    "stats.ttest_1samp(std, mu) #(standard deviation, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-critical value for 2 tailed test (hypothesis testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python to get the t-statistic & P-value\n",
    "# This is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. \n",
    "# This test assumes that the populations have identical variances by default.\n",
    "# Equal variance of false if comparing different size data\n",
    "stats.ttest_ind(sample_data_1, sample data_2, equal_var=False, nan_policy='omit') # nan_policy will omit the nan values in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a two-sided test for the null hypothesis that two independent samples have identical average (expected) values.\n",
    "# T-test for means of two independent samples from descriptive statistics.\n",
    "# T-test from data provided to get the statistics and p-value\n",
    "# nobs = number of observations aka n                                                                                \n",
    "stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate our t-critical value for 2 tailed test (.025 & .975) = 97% confidence\n",
    "print(stats.t.ppf(0.025, n-1)) # The degrees of freedom is (n-1)\n",
    "print(stats.t.ppf(0.975, n-1)) # The significance level is 97%\n",
    "\n",
    "# OR\n",
    "\n",
    "st.t.ppf(1-(.05/2), (n1 + n2)-2) # in one line - alpha devided by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Interval for Normally Distributed Data (margin of error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_std / np.sqrt(n) * z # or (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals for Non-Normally Distributed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ?\n",
    "mean = ?\n",
    "t_value = stats.t.ppf(0.95, n-1) # n-1 is the degrees of freedom, # The significance level is 97%\n",
    "margin_error = std / (np.sqrt(n)) * t\n",
    "confidence_interval = (mean - margin_error, mean + margin_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals for Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left endpt.: $\\hat{p} - z\\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$ <br/>\n",
    "right endpt.: $\\hat{p} + z\\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hat = ?\n",
    "n = ?\n",
    "z = stats.norm.ppf(0.975)\n",
    "step = z * np.sqrt(p_hat * (1-p_hat) / n) \n",
    "\n",
    "confidence_interval = (p_hat - step, p_hat + step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA - the $F$ test\n",
    "\n",
    "$F = \\frac{s^2_{between}}{s^2_{within}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of data\n",
    "np.random.seed(42)\n",
    "one = np.random.normal(0, 3, 100) #(center, std, n-points)\n",
    "two = np.random.normal(1, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"one-way\" just means that there is a single input variable.\n",
    "\n",
    "stats.f_oneway(one, two) # Can insert more than two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical p_values\n",
    "\n",
    "t = stats.ttest_ind(one, two, equal_var=True) # t-statistic squared = f-statistic, Variance should be the same (P-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The square of the two-sample t-stat = the F-stat\n",
    "t.statistic**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Formula to get the test statistic is : \n",
    "z = (p-p0) / âˆšp0(1-p0)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hat = x/n # Where x is the sample data and n is the total count of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 sample z prop test\n",
    "# if expected proportion = p1\n",
    "p0 = x_hat.mean()\n",
    "st_error = ((p0 * (1-p0))/ len(p0)**.5 # can use np.sqrt(p0) for square root\n",
    "z_stat = (p1 - p0) / st_error\n",
    "z_stat\n",
    "\n",
    "zcrit_val = st.norm.ppf(1-.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_null = 'H0: There is no statistically significant difference in the percentage of men and women who have a healthcare plan.'\n",
    "plan_alt = 'H1: There is a statistically significant difference in the percentage of men and women who have a healthcaare plan.'\n",
    "\n",
    "# 2 z prop test\n",
    "male_plan = df[df['SEX']==1]['HLTHPLN1']\n",
    "female_plan = df[df['SEX']==2]['HLTHPLN1']\n",
    "\n",
    "yesplan_m = male_chron[male_chron==1]\n",
    "yesplan_f = female_chron[female_chron==1]\n",
    "\n",
    "prob = (len(yesplan_m) + len(yesplan_f)) / (len(male_plan) + len(female_plan))\n",
    "p_hat_plan_male = len(yesplan_m)/len(male_plan)\n",
    "p_hat_plan_female = len(yesplan_f)/len(female_plan)\n",
    "den = (1/(len(male_plan)) + (1/len(female_plan)))\n",
    "num_plan = p_hat_plan_male - p_hat_plan_female\n",
    "den_plan =  (prob * (1-prob) * den)**.5\n",
    "\n",
    "#z statistic \n",
    "plan_z_2samp = num_plan / den_plan\n",
    "\n",
    "#crit val\n",
    "plan_zcrit_val1 = st.norm.ppf(1-.025)\n",
    "plan_zcrit_val2 = st.norm.ppf(1-.975)\n",
    "\n",
    "plan_z2sampprop_conclusion = 'Because the z-statistic is less than the critical value, we reject the null hypthesis.'\n",
    "plan_z2sampprop_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python one sided proportion Z test from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z test for proportions - https://www.statsmodels.org/stable/generated/statsmodels.stats.proportion.proportions_ztest.html\n",
    "# See url for examples\n",
    "proportions_ztest(count, nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python two sided proportion Z test from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = 0.025\n",
    "# our samples - 82% are good in one, and ~79% are good in the other\n",
    "# note - the samples do not need to be the same size\n",
    "sample_success_a, sample_size_a = (410, 500)\n",
    "sample_success_b, sample_size_b = (379, 400)\n",
    "# check our sample against Ho for Ha != Ho\n",
    "successes = np.array([sample_success_a, sample_success_b])\n",
    "samples = np.array([sample_size_, sample_size_b])\n",
    "# note, no need for a Ho value here - it's derived from the other parameters\n",
    "stat, p_value = proportions_ztest(count=successes, nobs=samples,  alternative='two-sided')\n",
    "# report\n",
    "print('z_stat: %0.3f, p_value: %0.3f' % (stat, p_value))\n",
    "if p_value > significance:\n",
    "   print (\"Fail to reject the null hypothesis - we have nothing else to say\")\n",
    "else:\n",
    "   print (\"Reject the null hypothesis - suggest the alternative hypothesis is true\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
