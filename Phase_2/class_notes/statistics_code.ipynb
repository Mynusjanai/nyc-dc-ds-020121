{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols                              #Regression Summary\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd        \n",
    "from statsmodels.stats import weightstats as stests                  #Z-test code\n",
    "from statsmodels.stats.proportion import proportions_ztest           #Proportions z-test\n",
    "from scipy.stats import chi2_contingency                             #Chi-squared test with similar proportions\n",
    "from scipy.stats import chi2                                         #Chi-squared\n",
    "from sklearn.linear_model import LinearRegression                    #Simple Linear Regression\n",
    "from sklearn.feature_selection import RFE                            #Multilinear Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler #Multilinear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPES OF ERRORS IN CALCULATIONS\n",
    "Type 1 errors (false positives) are when we accept an alternative hypothesis which is actually false.\n",
    "The  that we pick is the likelihood that we will get a type 1 error due to random chance.\n",
    "Type 2 errors (false negatives) are when we reject an alternative hypothesis which is actually true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATING HYPOTHESIS SOLUTION\n",
    "if (results[0]>t_crit) and (results[1]<alpha):\n",
    "    print (\"Null hypothesis rejected. Results are statistically significant with t-value =\", \n",
    "    round(results[0], 2), \"critical t-value =\", t_crit, \"and p-value =\", np.round((results[1]), 10))\n",
    "else:\n",
    "    print (\"Fail to reject the Null hypothesis with t-value =\", \n",
    "    round(results[0], 2), \", critical t-value =\", t_crit, \"and p-value =\", np.round((results[1]), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPOTHESIS TESTING - STEPS\n",
    "*1. Write down the null and alternative hypothesis you are testing.* \n",
    "*2. Select the appropriate test and calculate the test statistic and P-values.*\n",
    "*3. Determine the critical value for the 95% confidence interval.*\n",
    "*4. Evaluate the test statistic agains the critical value.*\n",
    "*5. Determine if you reject or fail to reject the null hypothesis and write a sentence explaining the results of your hypothesis test.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA\n",
    "all_data['PHYSHLTH'] = np.where((all_data.PHYSHLTH == 88),0,all_data.PHYSHLTH)\n",
    "all_data.drop(all_data[all_data['PHYSHLTH'].isin([77,99])].index, inplace = True)\n",
    "all_data.drop((all_data[all_data['SEX'] == 9].index), inplace = True)\n",
    "all_data['chronic'] = np.where(all_data['PHYSHLTH']>16, 1, 0)\n",
    "all_data.dropna(subset=['SMOKE100', 'SMOKDAY2'], how='all', inplace=True)\n",
    "conditions = [\n",
    "((all_data['ALCDAY5'] > 100) & (all_data['ALCDAY5'] < 108)), \n",
    "((all_data['ALCDAY5'] > 200) & (all_data['ALCDAY5'] < 231)),\n",
    "(all_data['ALCDAY5'] == 888)\n",
    "]\n",
    "choices = [ (all_data['ALCDAY5']-100)*4, (all_data['ALCDAY5']-200), 0 ]\n",
    "all_data['DAYSDRNK'] = np.select(conditions, choices, default=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT DATA\n",
    "all_data.head(), .describe(), .all_data['COLUMN'].value_counts()\n",
    "chron_data = all_data.groupby('_STATE')['chronic'].value_counts(normalize=True)\n",
    "y_vals = chron_data.iloc[chron_data.index.get_level_values('chronic') == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "fig, ax = plt.subplots()\n",
    "y_vals = list(all_data['PHYSHLTH'])\n",
    "\n",
    "ax.boxplot(y_vals)\n",
    "ax.hist(y_vals, bins=15)\n",
    "ax.bar(x_vals, y_vals)\n",
    "\n",
    "#multiple hist\n",
    "ax.hist(x_conn, bins=15, histtype='step', density=True, label='Conn')\n",
    "ax.hist(x_nj, bins=15, histtype='step', density=True, label='NJ')\n",
    "ax.hist(x_ny, bins=15, histtype='step', density=True, label='NY')\n",
    "\n",
    "#muliple bars\n",
    "ax.bar(x_vals, not_at_all_vals)\n",
    "ax.bar(x_vals, everyday_vals)\n",
    "ax.bar(x_vals, somedays_vals)\n",
    "\n",
    "ax.set_ylabel(\"# Days Sick\")\n",
    "ax.set_title(\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting 95% confidence interval from data- Is there a relationship between the number of Facebook likes for a cast and the box office gross of the movie?\n",
    "- Do foreign films perform differently at the box office than non-foreign films?\n",
    "- Of all movies created are 40% rated R?\n",
    "- Is there a relationship between the language of a film and the content rating (G, PG, PG-13, R) of that film?\n",
    "- Is there a relationship between the content rating of a film and its budget? \n",
    "df.dropna(subset=['gross'], inplace=True)\n",
    "df_r2k = df[(df['title_year'] > 2000) & (df['content_rating'] == 'R')]\n",
    "r2k_mean = df_r2k['gross'].mean()\n",
    "r2k_std = df_r2k['gross'].std()\n",
    "r2k_n = df_r2k['gross'].count()\n",
    "r2k_ci = stats.norm.interval(.95, loc=r2k_mean, scale=r2k_std/np.sqrt(r2k_n))\n",
    "\n",
    "print(f'mean = {r2k_mean}')\n",
    "print(f'std = {r2k_std}')\n",
    "print(f'n = {r2k_n}')\n",
    "print(f'The 95% confidence interval is {r2k_ci}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the type of test to use & null/alt hypothesis\n",
    "\n",
    "![img](img/choosing_test.png)\n",
    "\n",
    "1. Is there a relationship between the number of Facebook likes for a cast and the box office gross of the movie?\n",
    "* Simple Linear Regression\n",
    "* H0: The number of FB likes for a cast and the box office gross of a movie is related (beta = 0)\n",
    "* Ha: The number of FB likes for a cast and the box office gross of a movie is not related (beta != 0) \n",
    "<br><br>\n",
    "\n",
    "\n",
    "2. Do foreign films perform differently at the box office than non-foreign films?\n",
    "* Two sided t-test\n",
    "* H0: Foreign films perform the same at the box office than non-foreign films\n",
    "* Ha: There is a significant difference in performance at the box office between foreign and non-foreign films \n",
    "<br><br>\n",
    "\n",
    "\n",
    "3. Of all movies created are 40% rated R?\n",
    "* One sample z-test of proportion\n",
    "* H0: 40% of all movies created are rated R (P = .40)\n",
    "* Ha: 40% of all movies created are not rated R (P != .40) \n",
    "<br><br>\n",
    "\n",
    "\n",
    "4. Is there a relationship between the language of a film and the content rating (G, PG, PG-13, R) of that film?\n",
    "* Chi-Squared test\n",
    "* H0: Distributions of content ratings are correlated to the language of the film\n",
    "* Ha: Distributions of content ratings are not equal to the language of the film \n",
    "<br><br>\n",
    "\n",
    "\n",
    "5. Is there a relationship between the content rating of a film and its budget? \n",
    "* ANOVA\n",
    "* H0: The content rating of a film is directly correlated to its budget (content rating means are equal)\n",
    "* Ha: There is no relationship between content rating of a film and budget (means not equal, null hypothesis not true) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE-SAMPLE PERCENTAGE DATA VERSUS POPULATION Z-TEST\n",
    "z_stat = (x1_mean - pop_mean) / np.sqrt((pop_mean*(1-pop_mean))/n_count) #(x_hat - mu) / (std)\n",
    "\n",
    "#Z-score for when we are working with a sampling distribution:\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "\n",
    "#Critical Value of the Z score\n",
    "z_critical_val = st.norm.ppf(1-.05) # Where alpha is '.05'\n",
    "\n",
    "#Crit val for Z scores where comparing in 97% confidence\n",
    "zcrit_val1 = st.norm.ppf(1-.025)\n",
    "zcrit_val2 = st.norm.ppf(1-.975)\n",
    "\n",
    "#TWO-VARIABLE VERSUS EACH OTHER PERCENTAGE DATA Z-TEST\n",
    "p_val = (male_count_chronic + female_count_chronic) / (male_count + female_count)\n",
    "z_stat = np.round((male_mean - female_mean) / np.sqrt((p_ast*(1-p_ast)*(1/male_count + 1/female_count))),3)\n",
    "z_stat_calc = np.round(stats.ttest_ind(male_sample, female_sample, equal_var=True),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python function one sided Z-score from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statsmodels\n",
    "z_stat, p_value = proportions_ztest(count=sample_count, nobs=n, value=0.10, alternative='two-sided')\n",
    "\n",
    "#https://towardsdatascience.com/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce\n",
    "ztest ,pval = stests.ztest(df['bp_before'], x2=None, value=156)\n",
    "print(float(pval))\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python function two sided Z-score from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce\n",
    "ztest ,pval1 = stests.ztest(df['bp_before'], x2=df['bp_after'], value=0,alternative='two-sided')\n",
    "print(float(pval1))\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Percentile & Probability (hypothesis testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use stats to calculate the percentile / probablility of getting given z score OR higher\n",
    "print(\"Percentile = \", stats.norm.cdf(z)) # can use for t-value also\n",
    "\n",
    "# We can also use the survival function to calculate the probability\n",
    "print(\"Probability = \", stats.norm.sf(z)) # can use for t-value also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparing 2 means to see if they are equal or not equal. Correlation does not equal causation however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-critical value for 1 tailed test (hypothesis testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING T-CRITICAL VALUE\n",
    "t_critical = stats.norm.ppf(p_value)\n",
    "t_critical = stats.t.ppf(p_value, df=sample_num-1) #one-sample vs population t-test\n",
    "t_critical = stats.t.ppf(1-0.025, (male_count+female_count-2))\n",
    "p_value = stats.norm.pdf(z-score)\n",
    "p_value = stats.norm.cdf(z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Python to get the t-statistic & P-value for a 1 sample t-test:\n",
    "stats.ttest_1samp(std, mu) #(standard deviation, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-critical value for 2 tailed test (hypothesis testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO-TAILED ONE-SAMPLE VERSUS POPULATION T-TEST\n",
    "t_stat = (sample_mean - 4)/((sample_std/np.sqrt(sample_num)))\n",
    "results = stats.ttest_1samp(a=df['column_name'], popmean=4)\n",
    " \n",
    "# TWO-SAMPLE CONTINUOUS DATA VERSUS EACH OTHER T-TEST\n",
    "t_statistic = (x1_mean - x2_mean) / (np.sqrt(pool_var*((1/x1_count)+(1/x2_count))))\n",
    "t_stat, p_val = stats.ttest_ind(x1_sample, x2_sample, equal_var=True)\n",
    "\n",
    "# TWO-SAMPLE CONTINUOUS DATA BEFORE AND AFTER PAIRED T-TEST (same size)\n",
    "stats.ttest_rel(x1_sample, x2_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python to get the t-statistic & P-value\n",
    "# This is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. \n",
    "# This test assumes that the populations have identical variances by default.\n",
    "# Equal variance of false if comparing different size data\n",
    "stats.ttest_ind(sample_data_1, sample data_2, equal_var=False, nan_policy='omit') # nan_policy will omit the nan values in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a two-sided test for the null hypothesis that two independent samples have identical average (expected) values.\n",
    "# T-test for means of two independent samples from descriptive statistics.\n",
    "# T-test from data provided to get the statistics and p-value\n",
    "# nobs = number of observations aka n                                                                                \n",
    "stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate our t-critical value for 2 tailed test (.025 & .975) = 97% confidence\n",
    "print(stats.t.ppf(0.025, n-1)) # The degrees of freedom is (n-1)\n",
    "print(stats.t.ppf(0.975, n-1)) # The significance level is 97%\n",
    "\n",
    "# OR\n",
    "\n",
    "st.t.ppf(1-(.05/2), (n1 + n2)-2) # in one line - alpha devided by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two sided t-test from data frame\n",
    "# Assuming an alpha of .05\n",
    "df[df['country'] == 'USA'].dropna(subset=['country'])\n",
    "df[df['country'] != 'USA'].dropna(subset=['country'])\n",
    "\n",
    "domestic = df[df['country'] == 'USA']['gross']\n",
    "foreign = df[df['country'] != 'USA']['gross']\n",
    "domestic_mean = domestic.mean()\n",
    "foreign_mean = foreign.mean()\n",
    "domestic_std = domestic.std()\n",
    "foreign_std = foreign.std()\n",
    "domestic_n = domestic.count()\n",
    "foreign_n = foreign.count()\n",
    "\n",
    "print(stats.ttest_ind(foreign, domestic, equal_var=True, nan_policy='omit'))\n",
    "print(\"As the P_val is less than the alpha of .05, we reject the null hypothesis that foreign and domestic films perform the same at the box office\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Interval for Normally Distributed Data (margin of error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIDENCE INTERVAL FOR VALUE-based DATA\n",
    "standard_error = sample_std / np.sqrt(sample_num)\n",
    "lower_limit = sample_mean - (1.96 * standard_error)\n",
    "upper_limit = sample_mean + (1.96 * standard_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIDENCE INTERVAL FOR PERCENT-based DATA\n",
    "standard_error = np.sqrt((data_proportion*(1-data_proportion))/n_count)\n",
    "lower_limit = data_proportion - (z_val*standard_error)\n",
    "upper_limit = data_proportion + (z_val*standard_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_std / np.sqrt(n) * z # or (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals for Non-Normally Distributed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ?\n",
    "mean = ?\n",
    "t_value = stats.t.ppf(0.95, n-1) # n-1 is the degrees of freedom, # The significance level is 97%\n",
    "margin_error = std / (np.sqrt(n)) * t\n",
    "confidence_interval = (mean - margin_error, mean + margin_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals for Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left endpt.: $\\hat{p} - z\\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$ <br/>\n",
    "right endpt.: $\\hat{p} + z\\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hat = ?\n",
    "n = ?\n",
    "z = stats.norm.ppf(0.975)\n",
    "step = z * np.sqrt(p_hat * (1-p_hat) / n) \n",
    "\n",
    "confidence_interval = (p_hat - step, p_hat + step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA - the $F$ test\n",
    "\n",
    "$F = \\frac{s^2_{between}}{s^2_{within}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of data\n",
    "np.random.seed(42)\n",
    "one = np.random.normal(0, 3, 100) #(center, std, n-points)\n",
    "two = np.random.normal(1, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"one-way\" just means that there is a single input variable.\n",
    "\n",
    "stats.f_oneway(one, two) # Can insert more than two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical p_values\n",
    "\n",
    "t = stats.ttest_ind(one, two, equal_var=True) # t-statistic squared = f-statistic, Variance should be the same (P-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The square of the two-sample t-stat = the F-stat\n",
    "t.statistic**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE-WAY CONTINUOUS DATA MULTIPLE VARIABLE F-TEST\n",
    "f_data = {each_state:sample_populations['column_name'][sample_populations['subset_name'] == x] for x in n}\n",
    "f_stat, p_val = stats.f_oneway(f_data[9], f_data[34], f_data[36])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Formula to get the test statistic is : \n",
    "z = (p-p0) / âˆšp0(1-p0)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE-SAMPLE PERCENTAGE DATA VERSUS POPULATION Z-TEST OF PROPORTION\n",
    "z_stat = (x1_mean - pop_mean) / np.sqrt((pop_mean*(1-pop_mean))/n_count) #divided by the standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 sample z prop test\n",
    "# if expected proportion = p1\n",
    "p_hat = sample_mean\n",
    "p0 = pop_mean\n",
    "st_error = ((p0 * (1-p0))/ len(p0)**.5 # can use np.sqrt(p0) for square root\n",
    "z_stat = (p_hat - p0) / st_error\n",
    "\n",
    "zcrit_val = st.norm.ppf(1-.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TWO-VARIABLE VERSUS EACH OTHER PERCENTAGE DATA Z-TEST\n",
    "p_val = (male_count_chronic + female_count_chronic) / (male_count + female_count)\n",
    "z_stat = np.round((male_mean - female_mean) / np.sqrt((p_ast*(1-p_ast)*(1/male_count + 1/female_count))),3)\n",
    "z_stat_calc = np.round(stats.ttest_ind(male_sample, female_sample, equal_var=True),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hat = x/n # Where x is the sample data and n is the total count of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_null = 'H0: There is no statistically significant difference in the percentage of men and women who have a healthcare plan.'\n",
    "plan_alt = 'H1: There is a statistically significant difference in the percentage of men and women who have a healthcaare plan.'\n",
    "\n",
    "# 2 z prop test\n",
    "male_plan = df[df['SEX']==1]['HLTHPLN1']\n",
    "female_plan = df[df['SEX']==2]['HLTHPLN1']\n",
    "\n",
    "yesplan_m = male_chron[male_chron==1]\n",
    "yesplan_f = female_chron[female_chron==1]\n",
    "\n",
    "prob = (len(yesplan_m) + len(yesplan_f)) / (len(male_plan) + len(female_plan))\n",
    "p_hat_plan_male = len(yesplan_m)/len(male_plan)\n",
    "p_hat_plan_female = len(yesplan_f)/len(female_plan)\n",
    "den = (1/(len(male_plan)) + (1/len(female_plan)))\n",
    "num_plan = p_hat_plan_male - p_hat_plan_female\n",
    "den_plan =  (prob * (1-prob) * den)**.5\n",
    "\n",
    "#z statistic \n",
    "plan_z_2samp = num_plan / den_plan\n",
    "\n",
    "#crit val\n",
    "plan_zcrit_val1 = st.norm.ppf(1-.025)\n",
    "plan_zcrit_val2 = st.norm.ppf(1-.975)\n",
    "\n",
    "plan_z2sampprop_conclusion = 'Because the z-statistic is less than the critical value, we reject the null hypthesis.'\n",
    "plan_z2sampprop_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python one sided proportion Z test from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z test for proportions - https://www.statsmodels.org/stable/generated/statsmodels.stats.proportion.proportions_ztest.html\n",
    "# See url for examples\n",
    "z_stat, p_value = proportions_ztest(count=sample_count, nobs=n, value=0.10, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python two sided proportion Z test from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = 0.025\n",
    "# our samples - 82% are good in one, and ~79% are good in the other\n",
    "# note - the samples do not need to be the same size\n",
    "sample_success_a, sample_size_a = (410, 500)\n",
    "sample_success_b, sample_size_b = (379, 400)\n",
    "# check our sample against Ho for Ha != Ho\n",
    "successes = np.array([sample_success_a, sample_success_b])\n",
    "samples = np.array([sample_size_, sample_size_b])\n",
    "# note, no need for a Ho value here - it's derived from the other parameters\n",
    "stat, p_value = proportions_ztest(count=successes, nobs=samples,  alternative='two-sided')\n",
    "# report\n",
    "print('z_stat: %0.3f, p_value: %0.3f' % (stat, p_value))\n",
    "if p_value > significance:\n",
    "   print (\"Fail to reject the null hypothesis - we have nothing else to say\")\n",
    "else:\n",
    "   print (\"Reject the null hypothesis - suggest the alternative hypothesis is true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTIPLE VARIABLE VERSUS EACH OTHER PERCENTAGE DATA CHI-SQUARE TEST\n",
    "table = np.zeros((2, 3))\n",
    "for idx, value in enumerate(all_data['EVERMARRIED'].value_counts().index):\n",
    "    table[0, idx] = len(all_data[(all_data['NOALC'] == 0) & (all_data['EVERMARRIED'] == value)])\n",
    "    table[1, idx] = len(all_data[(all_data['NOALC'] == 1) & (all_data['EVERMARRIED'] == value)])\n",
    "chisq_test = stats.contingency.chi2_contingency(table)\n",
    "manual_chisq = np.divide((table - chisq_test[3])**2, chisq_test[3]).sum() #test of chi-square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect Size & Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EFFECT SIZE\n",
    "def Cohen_d(group1, group2):\n",
    "    diff = group1.mean() - group2.mean()\n",
    "    n1 = len(group1)\n",
    "    n2 = len(group2)\n",
    "    var1 = group1.var(ddof=1)\n",
    "    var2 = group2.var(ddof=1)\n",
    "    pooled_var = ((n1-1) * var1 + (n2-1) * var2) / (n1 + n2 - 2)\n",
    "    d = diff / np.sqrt(pooled_var)    \n",
    "    return d\n",
    "\n",
    "# POWER\n",
    "test = TTestIndPower()\n",
    "test.solve_power(alpha=alpha_default,nobs1=n_default, effect_size=d, power=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n",
    "\n",
    "For two random variables $X$ and $Y$, each with $n$ values:\n",
    "\n",
    "$\\sigma_{XY} = \\frac{\\Sigma^n_{i = 1}(x_i - \\mu_x)(y_i - \\mu_y)}{n}$ <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "\n",
    "Pearson Correlation: A correlation of -1 means that X and Y are perfectly negatively correlated, and a correlation of 1 means that X and Y are perfectly positively correlated. <br/>$\\ r_P = \\frac{\\Sigma^n_{i = 1}(x_i - \\mu_x)(y_i - \\mu_y)}{\\sqrt{\\Sigma^n_{i = 1}(x_i - \\mu_x)^2\\Sigma^n_{i = 1}(y_i -\\mu_y)^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 3, 5]\n",
    "Y = [2, 9, 10]\n",
    "\n",
    "# Covariance by hand:\n",
    "((1-3) * (2-7) + (3-3) * (9-7) + (5-3) * (10-7)) / 3\n",
    "\n",
    "# Better yet: With NumPy:\n",
    "np.cov(X, Y, ddof=0)[0, 1]\n",
    "\n",
    "np.cov(X, Y, ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X, Y)\n",
    "4 / np.sqrt(19)\n",
    "np.corrcoef(X, Y)[0, 1] == (np.cov(X, Y, ddof=0) / (np.std(X) * np.std(Y)))[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scipy function for Correlation\n",
    "stats.pearsonr(X, Y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Equation\n",
    "\n",
    "The solution for a simple regression best-fit line is as follows:\n",
    "\n",
    "- slope: <br/>$ m = r_P\\frac{\\sigma_y}{\\sigma_x} = \\frac{cov(X, Y)}{var(X)}$\n",
    "\n",
    "- y-intercept:<br/> $ b = \\mu_y - m\\mu_x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Without Error in `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y as a function of X. Y is target = dependent variable, X is predictor or independent variable\n",
    "sm.formula.ols(formula = \"y ~ x\", data = test_df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression with Error in `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20)\n",
    "y = np.array([3*pt + 5 + gauss(mu=0, sigma=5) for pt in x])\n",
    "\n",
    "df2 = pd.DataFrame(columns=['x', 'y'])\n",
    "\n",
    "df2['x'] = x\n",
    "df2['y'] = y\n",
    "\n",
    "model = sm.formula.ols(formula='y~x', data=df2).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features (independent variables) and target (dependent variable) from dataframe subset\n",
    "model_prep = df[['gross', 'budget', 'title_year', 'genres', 'imdb_score', 'actor_1_facebook_likes', \n",
    "                  'cast_total_facebook_likes', 'content_rating', 'language']]\n",
    "model_prep.dropna(subset=['title_year'], inplace=True)\n",
    "model_prep['years_old'] = 2021 - model_prep['title_year'].astype(int)\n",
    "model_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation\n",
    "model_prep.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables with pd.get_dummies\n",
    "summary_ols = pd.get_dummies(model_prep, columns=['content_rating']).drop(columns='content_rating_PG-13')\n",
    "\n",
    "# Or\n",
    "\n",
    "pd.get_dummies(comma_use.drop('RespondentID', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables with OneHotEncoder:\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "comma_trans = ohe.fit_transform(comma_use.drop('RespondentID', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating summary table\n",
    "film_lr = ols(formula='gross~cast_total_facebook_likes+budget+years_old+content_rating_G+content_rating_PG+content_rating_R', data=summary_ols).fit()\n",
    "film_lr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset('diamonds').drop(['cut', 'color', 'clarity'], axis = 1)\n",
    "X, y = data.drop('price', axis=1), data['price']\n",
    "model2 = sm.OLS(y, X).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.plot_regress_exog(model2, 'carat', fig=plt.figure(figsize=(12, 8)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model with log-scaled target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scld = np.log(y)\n",
    "y_scld.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = sm.OLS(y_scld, X).fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting log-scaled target\n",
    "sm.graphics.plot_regress_exog(model3, 'carat', fig=plt.figure(figsize=(12, 8)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember that $R^2$ can be negative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pred = np.mean(y) * np.ones(len(y))\n",
    "worse_pred = (np.mean(y) + 1000) * np.ones(len(y))\n",
    "\n",
    "print(metrics.r2_score(y, bad_pred))\n",
    "print(metrics.r2_score(y, worse_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Regression\n",
    "\n",
    "First, we'll separate the data into our predictors (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_preds = wine.drop('quality', axis=1)\n",
    "wine_target = wine['quality']\n",
    "wine_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating constant term/y-intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sm.add_constant() to add constant term/y-intercept\n",
    "predictors = sm.add_constant(wine_preds)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary on data with new constant\n",
    "model = sm.OLS(wine_target, predictors).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll include all the columns for now.\n",
    "# Z score calculation: n - mean of dataset / std of dataset\n",
    "wine_preds_scaled = (wine_preds - np.mean(wine_preds)) / np.std(wine_preds)\n",
    "\n",
    "predictors = sm.add_constant(wine_preds_scaled)\n",
    "model = sm.OLS(wine_target, predictors).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression in Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a StandardScaler object to scale our data for us.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Now we'll apply it to our data by using the .fit() and .transform() methods.\n",
    "ss.fit(wine_preds)\n",
    "\n",
    "wine_preds_st_scaled = ss.transform(wine_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the scaling worked about the same as when we did it by hand\n",
    "np.allclose(wine_preds_st_scaled, wine_preds_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values add up to original pandas df\n",
    "wine_preds_st_scaled[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit a LinearRegression object to our training data!\n",
    "lr = LinearRegression()\n",
    "lr.fit(wine_preds_st_scaled, wine_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the .coef_ attribute to recover the results\n",
    "# of the regression.\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)\n",
    "print(lr.score(wine_preds_st_scaled, wine_target))\n",
    "print(lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics module in sklearn has a number of metrics that we can use to meaure the accuracy of our model, \n",
    "including the $R^2$ score, the mean absolute error and the mean squared error. \n",
    "Note that the default 'score' on our model object is the $R^2$ score. Let's go back to our wine dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure this metric is properly calibrated. If we put simply $\\bar{y}$ as our prediction, then we should get an $R^2$ score of *0*. And if we predict, say, $\\bar{y} + 1$, then we should get a *negative* $R^2$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_quality = np.mean(wine_target)\n",
    "num = len(wine_target)\n",
    "\n",
    "metrics.r2_score(wine_target, avg_quality * np.ones(num))\n",
    "\n",
    "metrics.r2_score(wine_target, (avg_quality + 1) * np.ones(num))\n",
    "\n",
    "metrics.mean_absolute_error(wine_target, lr.predict(wine_preds_st_scaled))\n",
    "\n",
    "metrics.mean_squared_error(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B) = \\frac{P(B|A)}{P(B)}\\ P(A) $$\n",
    "\n",
    "$$P(A|B) =  \\frac{P(B|A)*P(A)}{P(B)}$$\n",
    "\n",
    "$$P(A|B) =  \\frac{P(B|A)*P(A)}{P(B|A)*P(A) + P(B|not_A)*P(not_A)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each part (note, depending how you approach this, you might group different parts together):\n",
    "\n",
    "- $P(A)$: *prior*\n",
    "- $P(A|B)$: *posterior*\n",
    "- $P(B|A)$: *likelihood*\n",
    "- $\\frac{1}{P(B)}$: *normalization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advertising executive is studying television viewing habits of married men and women during prime time hours. Based on the past viewing records he has determined that during prime time wives are watching television 60% of the time. It has also been determined that when the wife is watching television, 40% of the time the husband is also watching. When the wife is not watching the television, 30% of the time the husband is watching the television. Find the probability that if the husband is watching the television, the wife is also watching the television."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes Theorem from above problem\n",
    "P_a = .6           #prob of wife watching tv\n",
    "P_b_given_a = .4   #prob of husband watching tv given wife watching tv\n",
    "P_b_not_a = .3     #prob of husband watching tv given wife not watching tv\n",
    "P_not_a = .4       #prob of wife not watching tv\n",
    "\n",
    "P_a_given_b = (P_a * P_b_given_a) / (P_a * P_b_given_a + P_not_a * P_b_not_a)\n",
    "\n",
    "print(f'Probability that the wife is watching tv given the husband is watching tv is: {P_a_given_b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
